{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49bd31f1-2e2f-4897-ae07-b1048b7d2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import sqlite3\n",
    "import jsonlines\n",
    "from collections import Counter\n",
    "from unicodedata import normalize\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, Flatten\n",
    "# from tensorflow.keras.models import Model, load_model\n",
    "# from tensorflow.keras.regularizers import l1, l2\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.utils import Sequence\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "# from sklearn.metrics import f1_score, precision_score, recall_score,confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41cb9fb-03bc-4d4f-9c17-2d0b05cdcb74",
   "metadata": {},
   "source": [
    "# split big jsonl files to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a34996e-6903-469c-9853-51943f843e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = os.listdir(r\"C:\\Users\\Saba\\Desktop\\Python\\AI CS hackathon btu\\datasets\\websites\\comprehensive_dataset\")\n",
    "def replace_unnecessary_symbols(text):\n",
    "    filters = '1234567890!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r\\b'\n",
    "    translate_dict = {c: \" \" for c in filters}\n",
    "    text = text.lower()\n",
    "    # Create a translation table\n",
    "    translation_table = str.maketrans(translate_dict)\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    html_translate_dict = {\" href \":\" \",\n",
    "                           \" src \": \" \",\n",
    "                           \" vc \":\" \",\n",
    "                           \"jpg\":\" \",\n",
    "                          \" en \":\" \",\n",
    "                          \"thumb\":\" \",\n",
    "                          'title':\" \",\n",
    "                          \" com \": \" \",\n",
    "                          \" https \":\" \",\n",
    "                          \" ru \":\" \",\n",
    "                          \" net \": \" \",\n",
    "                          # \"\\u00a9\":\" \",\n",
    "                          \" tags \":\" \",\n",
    "                          \" hd \":\" \"\n",
    "                          # '\\u0308':\" \"\n",
    "                          }\n",
    "    # html_translation_table = str.maketrans(html_translate_dict)\n",
    "    # Use translate method\n",
    "    new_text = text.translate(translation_table)\n",
    "    for key in html_translate_dict:\n",
    "        new_text = new_text.replace(key,html_translate_dict[key])\n",
    "    new_text = re.sub(r'\\s+', ' ', new_text)\n",
    "    return new_text\n",
    "\n",
    "\n",
    "def save_json(filepath_to_save,json_index,dict,name):\n",
    "    with open(f'{filepath_to_save}/{name}_cleaned_{json_index}.json', 'w') as f:\n",
    "        json.dump(dict, f, indent=4)\n",
    "\n",
    "\n",
    "def save_to_chunks(name,file):\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    chunks = pd.read_json(file, lines=True, chunksize=1)\n",
    "    num = 1\n",
    "    total_chunks = 370425  # Total number of chunks to process\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            html_content = chunk[\"html\"].values[0]\n",
    "            soup  = BeautifulSoup(html_content, 'html')\n",
    "        except:\n",
    "            print(f\"could not parse row number {num}\")\n",
    "            continue\n",
    "        \n",
    "        for tag in soup(['script', 'style', 'img',\"input\",'iframe']):\n",
    "            tag.decompose()\n",
    "        for a_tag in soup.find_all('a'):\n",
    "            del a_tag['href']\n",
    "        for tag in soup.find_all(True):  # True selects all tags\n",
    "            if 'style' in tag.attrs:\n",
    "                del tag.attrs['style'] \n",
    "            if 'class' in tag.attrs:\n",
    "                del tag.attrs['class']\n",
    "            if 'target' in tag.attrs:\n",
    "                del tag.attrs['target']\n",
    "                \n",
    "        # we should get rid of tab and escape charaters, also weird symbols and replace duplicate spaces with one space\n",
    "        html_text = soup.get_text(separator=' ')\n",
    "        html_text = normalize('NFKD', html_text)\n",
    "        \n",
    "        html_text = replace_unnecessary_symbols(html_text)\n",
    "        \n",
    "        url = normalize('NFKD', chunk['url'].values[0])\n",
    "        label = chunk['label'].values[0]\n",
    "        \n",
    "        processed_json = {\n",
    "            \"url\":url,\n",
    "            \"label\":label,\n",
    "            \"html\":html_text\n",
    "        }\n",
    "        filepath_to_save = 'C:/Users/Saba/Desktop/Python/AI CS hackathon btu/datasets/websites/comprehensive_chunks_cleaned_malicious'\n",
    "        save_json(filepath_to_save,num,processed_json,name)\n",
    "        if num % 50 == 0:\n",
    "             \n",
    "            # Calculate elapsed time and remaining time\n",
    "            elapsed_time = time.time() - start_time\n",
    "            avg_time_per_chunk = elapsed_time / num\n",
    "            remaining_chunks = total_chunks - num\n",
    "            remaining_time = remaining_chunks * avg_time_per_chunk\n",
    "            \n",
    "            # Convert remaining time to minutes and seconds\n",
    "            remaining_minutes = int(remaining_time // 60)\n",
    "            remaining_seconds = int(remaining_time % 60)\n",
    "            \n",
    "            print(f\"Processed {num}/{total_chunks} chunks. Estimated time left: {remaining_minutes}m {remaining_seconds}s\", end='\\r')\n",
    "\n",
    "        num +=1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59d8994-8f4c-4194-925b-989e5860bd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Saba/Desktop/Python/AI CS hackathon btu/datasets/websites/comprehensive_dataset/malicious_OWS_URL_HTML_DS.jsonl\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "file = \"C:/Users/Saba/Desktop/Python/AI CS hackathon btu/datasets/websites/comprehensive_dataset/\"+datasets[3]\n",
    "print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32d05ea1-9407-4248-bfc3-c7200deb35f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 650/370425 chunks. Estimated time left: 171m 25s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2100/370425 chunks. Estimated time left: 108m 25s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3000/370425 chunks. Estimated time left: 100m 56s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3200/370425 chunks. Estimated time left: 102m 31s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3400/370425 chunks. Estimated time left: 101m 16s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3600/370425 chunks. Estimated time left: 100m 31s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4200/370425 chunks. Estimated time left: 96m 37ss\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7250/370425 chunks. Estimated time left: 88m 48s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8500/370425 chunks. Estimated time left: 87m 31s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8600/370425 chunks. Estimated time left: 87m 29s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8950/370425 chunks. Estimated time left: 86m 47s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 9450/370425 chunks. Estimated time left: 86m 3ss\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 11450/370425 chunks. Estimated time left: 85m 12s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 12150/370425 chunks. Estimated time left: 84m 33s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 12700/370425 chunks. Estimated time left: 84m 30s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not parse row number 12797stimated time left: 84m 25s\n",
      "Processed 13150/370425 chunks. Estimated time left: 84m 8ss\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not parse row number 13175\n",
      "Processed 13500/370425 chunks. Estimated time left: 83m 53s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 13600/370425 chunks. Estimated time left: 83m 38s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 13800/370425 chunks. Estimated time left: 83m 41s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14150/370425 chunks. Estimated time left: 83m 28s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14250/370425 chunks. Estimated time left: 83m 23s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14400/370425 chunks. Estimated time left: 83m 23s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14950/370425 chunks. Estimated time left: 83m 15s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15100/370425 chunks. Estimated time left: 83m 5ss\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15700/370425 chunks. Estimated time left: 82m 28s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15800/370425 chunks. Estimated time left: 82m 26s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 16050/370425 chunks. Estimated time left: 82m 18s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 17150/370425 chunks. Estimated time left: 81m 57s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 17350/370425 chunks. Estimated time left: 81m 47s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 17700/370425 chunks. Estimated time left: 81m 38s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 19500/370425 chunks. Estimated time left: 81m 6ss\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not parse row number 19796stimated time left: 80m 56s\n",
      "Processed 20000/370425 chunks. Estimated time left: 80m 48s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20950/370425 chunks. Estimated time left: 80m 19s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 21750/370425 chunks. Estimated time left: 80m 1ss\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 21900/370425 chunks. Estimated time left: 80m 4s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not parse row number 22033stimated time left: 80m 2s\n",
      "Processed 22300/370425 chunks. Estimated time left: 79m 48s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 22450/370425 chunks. Estimated time left: 79m 44s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 22500/370425 chunks. Estimated time left: 79m 41s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 23300/370425 chunks. Estimated time left: 79m 6ss\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not parse row number 23428stimated time left: 79m 3s\n",
      "Processed 24150/370425 chunks. Estimated time left: 78m 38s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 24750/370425 chunks. Estimated time left: 78m 24s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n",
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 25200/370425 chunks. Estimated time left: 78m 13s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 26000/370425 chunks. Estimated time left: 77m 56s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 26150/370425 chunks. Estimated time left: 77m 49s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 26300/370425 chunks. Estimated time left: 77m 52s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 26450/370425 chunks. Estimated time left: 77m 46s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 27500/370425 chunks. Estimated time left: 77m 8ss\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 28800/370425 chunks. Estimated time left: 76m 36s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 29200/370425 chunks. Estimated time left: 76m 19s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 29500/370425 chunks. Estimated time left: 76m 4ss\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not parse row number 31273stimated time left: 75m 13s\n",
      "Processed 31550/370425 chunks. Estimated time left: 75m 18s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 32000/370425 chunks. Estimated time left: 75m 2ss\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 32150/370425 chunks. Estimated time left: 74m 57s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 32200/370425 chunks. Estimated time left: 74m 57s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 32350/370425 chunks. Estimated time left: 74m 56s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 32850/370425 chunks. Estimated time left: 74m 43s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 33050/370425 chunks. Estimated time left: 74m 37s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n",
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not parse row number 33140stimated time left: 74m 34s\n",
      "Processed 33750/370425 chunks. Estimated time left: 74m 14s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 34500/370425 chunks. Estimated time left: 73m 52s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 34750/370425 chunks. Estimated time left: 73m 51s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 35250/370425 chunks. Estimated time left: 73m 38s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not parse row number 35434stimated time left: 73m 34s\n",
      "Processed 35700/370425 chunks. Estimated time left: 73m 21s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 35800/370425 chunks. Estimated time left: 73m 17s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 36000/370425 chunks. Estimated time left: 73m 14s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 36100/370425 chunks. Estimated time left: 73m 13s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 36150/370425 chunks. Estimated time left: 73m 11s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 36500/370425 chunks. Estimated time left: 72m 57s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 36800/370425 chunks. Estimated time left: 72m 56s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 39700/370425 chunks. Estimated time left: 71m 58s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\AppData\\Local\\Temp\\ipykernel_27288\\2841664123.py:49: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  soup  = BeautifulSoup(html_content, 'html')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 39850/370425 chunks. Estimated time left: 71m 54s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saba\\.conda\\envs\\AI\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 39950/370425 chunks. Estimated time left: 71m 52s\r"
     ]
    }
   ],
   "source": [
    "save_to_chunks(\"malicious\",file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e58b58-f4f2-49d4-80e7-4b92bf3d4548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa3a64-aeb1-4669-9962-54cd9fe410be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e20dc972-15d5-428f-9fcb-e9ef7229ccbb",
   "metadata": {},
   "source": [
    "# Load chunks of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "988f0545-abf3-4bb0-b917-c1f3487c7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunk_to_dataframe(chunk_index):\n",
    "    chunks_filepath = \"C:/Users/Saba/Desktop/Python/AI CS hackathon btu/datasets/websites/comprehensive_chunks_parsed/\"\n",
    "    chunks = os.listdir(chunks_filepath)\n",
    "    chunk_fullpath = chunks_filepath+chunks[chunk_index]\n",
    "    df = pd.read_json(chunk_fullpath)\n",
    "    # df.drop(columns=[\"sublabel\",'crawled','uid'],inplace=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec85d60c-2b8a-4552-8908-962ebf9bb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_filepath = \"C:/Users/Saba/Desktop/Python/AI CS hackathon btu/datasets/websites/comprehensive_chunks_parsed/\"\n",
    "chunks = os.listdir(chunks_filepath)\n",
    "chunks_length = len(chunks)\n",
    "# print(chunks_length)\n",
    "json_files_full = [chunks_filepath+chunk for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d22ba5-5f8e-4f70-9a72-3cd58620b4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
