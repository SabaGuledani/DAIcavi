{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49bd31f1-2e2f-4897-ae07-b1048b7d2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import sqlite3\n",
    "import jsonlines\n",
    "from collections import Counter\n",
    "from unicodedata import normalize\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41cb9fb-03bc-4d4f-9c17-2d0b05cdcb74",
   "metadata": {},
   "source": [
    "# split big jsonl files to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8a34996e-6903-469c-9853-51943f843e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = os.listdir(r\"C:\\Users\\Saba\\Desktop\\Python\\AI CS hackathon btu\\datasets\\websites\\comprehensive_dataset\")\n",
    "def save_to_chunks(name,file):\n",
    "    \n",
    "    chunks = pd.read_json(file, lines=True, chunksize=1)\n",
    "    num = 1\n",
    "    for chunk in chunks:\n",
    "        filename = f'C:/Users/Saba/Desktop/Python/AI CS hackathon btu/datasets/websites/comprehensive_chunks_parsed/{name}_chunk_{num}.json'\n",
    "        if num % 1000 == 0:\n",
    "            print(filename)\n",
    "        try:\n",
    "            html_content = chunk[\"html\"].values[0]\n",
    "            soup  = BeautifulSoup(html_content, 'html')\n",
    "        except:\n",
    "            print(f\"could not parse row number {num}\")\n",
    "            continue\n",
    "            \n",
    "        # we should get rid of tab and escape charaters, also weird symbols and replace duplicate spaces with one space\n",
    "        chunk[\"html_text\"] = soup.get_text(separator=' ').replace('\\t',\" \").replace(\"\\n\",\" \").replace(\"\\u00f8t\",\" \").replace(\"  \",\"\")\n",
    "        if name == \"benign\":\n",
    "            columns_to_drop = ['uid','sublabel',\"html\",\"Language\"]\n",
    "        elif name == \"adult\":\n",
    "            columns_to_drop = ['uid','sublabel',\"html\",\"crawled\"]\n",
    "        else:\n",
    "            columns_to_drop = ['sublabel',\"html\",\"source\",\"status_code\"]\n",
    "        chunk.drop(columns=columns_to_drop, inplace=True)\n",
    "        chunk.to_json(filename)\n",
    "        if num % 40000 == 0:\n",
    "            break\n",
    "        num +=1\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b59d8994-8f4c-4194-925b-989e5860bd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Saba/Desktop/Python/AI CS hackathon btu/datasets/websites/comprehensive_dataset/adult_OWS_URL_HTML_DS.jsonl\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "file = \"C:/Users/Saba/Desktop/Python/AI CS hackathon btu/datasets/websites/comprehensive_dataset/\"+datasets[0]\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa3a64-aeb1-4669-9962-54cd9fe410be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_to_chunks(\"adult\",file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20dc972-15d5-428f-9fcb-e9ef7229ccbb",
   "metadata": {},
   "source": [
    "# Load chunks of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988f0545-abf3-4bb0-b917-c1f3487c7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunk_to_dataframe(chunk_index):\n",
    "    chunks_filepath = \"C:/Users/Saba/Desktop/Python/AI CS hackathon btu/datasets/websites/comprehensive_chunks_parsed/\"\n",
    "    chunks = os.listdir(chunks_filepath)\n",
    "    chunk_fullpath = chunks_filepath+chunks[chunk_index]\n",
    "    df = pd.read_json(chunk_fullpath)\n",
    "    # df.drop(columns=[\"sublabel\",'crawled','uid'],inplace=True)\n",
    "    return df\n",
    "\n",
    "def replace_unnecessary_symbols(text):\n",
    "    replace_dict = {\n",
    "        '1': '',\n",
    "        '2': '',\n",
    "        '3': '',\n",
    "        '4': '',\n",
    "        '5': '',\n",
    "        '6': '',\n",
    "        '7': '',\n",
    "        '8': '',\n",
    "        '9': '',\n",
    "        '0': '', \n",
    "        '.': ' ',\n",
    "        ',': ' ',\n",
    "        '|': '',\n",
    "        '_': ' ',\n",
    "        '\"': '',\n",
    "        '\\'': '',\n",
    "        '\\r':\" \",\n",
    "        ':': ' ',\n",
    "        '/': '',\n",
    "        '&': '',\n",
    "        '%': '',\n",
    "        '#': '',\n",
    "        '@': '',\n",
    "        '!': '',\n",
    "        '<': '',\n",
    "        '>': '',\n",
    "    }\n",
    "    \n",
    "    # Create a translation table\n",
    "    translation_table = str.maketrans(replace_dict)\n",
    "    \n",
    "    # Use translate method\n",
    "    new_text = text.translate(translation_table)\n",
    "    new_text = new_text.replace(\"  \",\" \")\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec85d60c-2b8a-4552-8908-962ebf9bb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_filepath = \"C:/Users/Saba/Desktop/Python/AI CS hackathon btu/datasets/websites/comprehensive_chunks_parsed/\"\n",
    "chunks = os.listdir(chunks_filepath)\n",
    "chunks_length = len(chunks)\n",
    "# print(chunks_length)\n",
    "json_files_full = [chunks_filepath+chunk for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b80d2a57-c2e4-4bcc-b31e-9464f46a68c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_json_file(json_file):\n",
    "    with open(json_file,'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    key = list(json_data['html_text'].keys())[0]\n",
    "    html_text = normalize('NFKD', json_data['html_text'][key])\n",
    "    html_text = replace_unnecessary_symbols(html_text)\n",
    "    return html_text\n",
    "\n",
    "\n",
    "def process_json_files(json_files):\n",
    "    jsons_length = len(json_files)\n",
    "    texts_list = []\n",
    "    \n",
    "    for json_index in range(jsons_length-1):\n",
    "        json_file = json_files[json_index]\n",
    "        extracted_text = process_json_file(json_file)\n",
    "        \n",
    "        texts_list.append(extracted_text)\n",
    "        \n",
    "        if json_index % 50 == 0 and json_index != 0:\n",
    "            print(json_index, end='\\r')\n",
    "    return texts_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671380c-acb9-4259-8f79-86aa961501a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_list = process_json_files(json_files_full)\n",
    "print(len(texts_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633d3ca-d369-42d5-9477-d4eca01220c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('htmls_parsed_text_list.pkl', 'wb') as f:\n",
    "    pickle.dump(texts_list, f)\n",
    "    print(\"list saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e36d8b-22d2-40ab-b49c-3f2d01c4e172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268c797-5091-4142-ac1d-5e7968ee92cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b9f5d0-f473-4534-8d4f-c020181e036d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c602ce2e-db66-435f-8b5a-c97e5e89e8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa993d65-09d8-43d8-a1d4-0c210d408d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e6e29-e83f-4a70-b75c-50911e04e7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c703f97-6ccb-466a-add8-db3b030b30d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e98ab-ca0d-489e-9c48-c4c2616ba720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b7f53-9912-4ae3-8473-efef0f6e4b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3134f47a-87a3-43c7-a1c3-37576636a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/Saba/Desktop/Python/AI CS hackathon btu/datasets/images/dickpics/german_mydickpictures_links.txt',\"r\") as f:\n",
    "    lines = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac69b614-15e0-4c84-90a7-b508e4c2bde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9396\n"
     ]
    }
   ],
   "source": [
    "print(len(lines[79544:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d22ba5-5f8e-4f70-9a72-3cd58620b4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
